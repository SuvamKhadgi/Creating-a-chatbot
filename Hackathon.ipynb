{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b65dd0-9f94-4646-8eb2-0cdf6f86fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Function to convert text to speech\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to get a yes or no confirmation from the user\n",
    "def get_confirmation(prompt):\n",
    "    while True:\n",
    "        speak(prompt)\n",
    "        with sr.Microphone() as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio_data = recognizer.listen(source)\n",
    "            try:\n",
    "                response = recognizer.recognize_google(audio_data).lower()\n",
    "                if 'yes' in response:\n",
    "                    return True\n",
    "                elif 'no' in response:\n",
    "                    return False\n",
    "                else:\n",
    "                    speak(\"Please say yes or no.\")\n",
    "            except sr.UnknownValueError:\n",
    "                speak(\"I did not understand that. Please try again.\")\n",
    "            except sr.RequestError as e:\n",
    "                speak(f\"Error with the speech recognition service; {e}\")\n",
    "\n",
    "# Function to get user input for a prompt and confirm it\n",
    "def get_input(prompt):\n",
    "    while True:\n",
    "        speak(prompt)\n",
    "        with sr.Microphone() as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio_data = recognizer.listen(source)\n",
    "            try:\n",
    "                input_text = recognizer.recognize_google(audio_data)\n",
    "                speak(f\"You said: {input_text}. Is that correct? Please say yes or no.\")\n",
    "                if get_confirmation(\"Is that correct?\"):\n",
    "                    return input_text\n",
    "                else:\n",
    "                    speak(\"Let's try again.\")\n",
    "            except sr.UnknownValueError:\n",
    "                speak(\"I did not understand that. Please try again.\")\n",
    "            except sr.RequestError as e:\n",
    "                speak(f\"Error with the speech recognition service; {e}\")\n",
    "\n",
    "# Main process\n",
    "def main():\n",
    "    speak(\"Hello, I will first ask for your phone number.\")\n",
    "    phone_number = get_input(\"Please say your phone number.\")\n",
    "    speak(\"Thank you. Now I will ask for your email.\")\n",
    "    email = get_input(\"Please say your email address.\")\n",
    "    \n",
    "    speak(f\"Your phone number is {phone_number} and your email is {email}. Is that correct?\")\n",
    "    if get_confirmation(\"Is the provided information correct?\"):\n",
    "        print(f\"Stored Phone Number: {phone_number}\")\n",
    "        print(f\"Stored Email: {email}\")\n",
    "        speak(\"Thank you. Your information has been saved.\")\n",
    "    else:\n",
    "        speak(\"Let's start over.\")\n",
    "        main()\n",
    "\n",
    "main()\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10719544-70f0-42ab-b969-d09d193fd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    # Capture video frames\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert frame to RGB format\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Convert frame to PIL Image\n",
    "        image = Image.fromarray(frame)\n",
    "        # Convert PIL Image to ImageTk format\n",
    "        image_tk = ImageTk.PhotoImage(image)\n",
    "        \n",
    "        # Update the canvas image\n",
    "        canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "        canvas.image = image_tk\n",
    "        \n",
    "        # Call this function again after a delay\n",
    "        root.after(10, play_video)\n",
    "    else:\n",
    "        # If video ends, release the capture object\n",
    "        cap.release()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture('C:/Users/rujan/Videos/Captures/output.avi')\n",
    "\n",
    "# Start playing video\n",
    "play_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa4c13-1ab8-4ac1-bb80-f57d5ca81f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video\n",
    "    if playing_video:\n",
    "        # Capture video frames\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Convert frame to RGB format\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert frame to PIL Image\n",
    "            image = Image.fromarray(frame)\n",
    "            # Convert PIL Image to ImageTk format\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            \n",
    "            # Update the canvas image\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            \n",
    "            # Call this function again after a delay\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            # If video ends, release the capture object\n",
    "            cap.release()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture('C:/Users/rujan/Videos/Captures/output.avi')\n",
    "\n",
    "def speak(text):\n",
    "    start_video()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    stop_video()\n",
    "\n",
    "print(\"Listening... Say 'stop' to end the program.\")\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Please speak now.\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Listen for the user's input\n",
    "                audio_data = recognizer.listen(source)\n",
    "                print(\"Recognizing...\")\n",
    "                \n",
    "                # Recognize the speech using Google Web Speech API\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "                print(f\"You said: {text}\")\n",
    "\n",
    "                # Respond with speech\n",
    "                if text.lower() == \"stop\":\n",
    "                    speak(\"Stopping the program.\")\n",
    "                    break                    \n",
    "                else:\n",
    "                    speak(f\"You said: {text}\")\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Speech recognition could not understand the audio.\")\n",
    "                speak(\"I did not understand that. Please try again.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"Could not request results from the speech recognition service; {e}\")\n",
    "                speak(\"There was an error with the speech recognition service.\")\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "import threading\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    " \n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d2231-53f0-4cba-a4ba-10b67fa7e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Initialize a queue for managing TTS requests\n",
    "tts_queue = Queue()\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video\n",
    "    if playing_video:\n",
    "        # Capture video frames\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Convert frame to RGB format\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert frame to PIL Image\n",
    "            image = Image.fromarray(frame)\n",
    "            # Convert PIL Image to ImageTk format\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            \n",
    "            # Update the canvas image\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            \n",
    "            # Call this function again after a delay\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            # If video ends, release the capture object\n",
    "            cap.release()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    tts_queue.put(text)\n",
    "\n",
    "# Function to process the TTS queue\n",
    "def process_tts_queue():\n",
    "    while True:\n",
    "        text = tts_queue.get()\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        tts_queue.task_done()\n",
    "\n",
    "# Start a thread to process the TTS queue\n",
    "tts_thread = threading.Thread(target=process_tts_queue, daemon=True)\n",
    "tts_thread.start()\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        speak(\"Listening for your question...\")\n",
    "        audio_data = recognizer.listen(source)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            speak(\"I could not understand what you said. Please try again.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)  # Give Rasa some time to start\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to get a yes or no confirmation from the user\n",
    "def get_confirmation(prompt):\n",
    "    while True:\n",
    "        speak(prompt)\n",
    "        with sr.Microphone() as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio_data = recognizer.listen(source)\n",
    "            try:\n",
    "                response = recognizer.recognize_google(audio_data).lower()\n",
    "                if 'yes' in response:\n",
    "                    return True\n",
    "                elif 'no' in response:\n",
    "                    return False\n",
    "                else:\n",
    "                    speak(\"Please say yes or no.\")\n",
    "            except sr.UnknownValueError:\n",
    "                speak(\"I did not understand that. Please try again.\")\n",
    "            except sr.RequestError as e:\n",
    "                speak(f\"Error with the speech recognition service; {e}\")\n",
    "\n",
    "# Function to get user input for a prompt and confirm it\n",
    "def get_input(prompt):\n",
    "    while True:\n",
    "        speak(prompt)\n",
    "        with sr.Microphone() as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio_data = recognizer.listen(source)\n",
    "            try:\n",
    "                input_text = recognizer.recognize_google(audio_data)\n",
    "                speak(f\"You said: {input_text}. Is that correct? Please say yes or no.\")\n",
    "                if get_confirmation(\"Is that correct?\"):\n",
    "                    return input_text\n",
    "                else:\n",
    "                    speak(\"Let's try again.\")\n",
    "            except sr.UnknownValueError:\n",
    "                speak(\"I did not understand that. Please try again.\")\n",
    "            except sr.RequestError as e:\n",
    "                speak(f\"Error with the speech recognition service; {e}\")\n",
    "\n",
    "# Function to enroll user by asking for phone number and email\n",
    "def enroll_user():\n",
    "    speak(\"Hello, I will first ask for your phone number.\")\n",
    "    phone_number = get_input(\"Please say your phone number.\")\n",
    "    speak(\"Thank you. Now I will ask for your email.\")\n",
    "    email = get_input(\"Please say your email address.\")\n",
    "    \n",
    "    speak(f\"Your phone number is {phone_number} and your email is {email}. Is that correct?\")\n",
    "    if get_confirmation(\"Is the provided information correct?\"):\n",
    "        print(f\"Stored Phone Number: {phone_number}\")\n",
    "        print(f\"Stored Email: {email}\")\n",
    "        speak(\"Thank you. Your information has been saved.\")\n",
    "    else:\n",
    "        speak(\"Let's start over.\")\n",
    "        enroll_user()\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            elif \"enroll\" in question.lower():\n",
    "                enroll_user()\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                speak(response)\n",
    "        time.sleep(1)  # Pause for a moment before the next iteration\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture('C:/Users/rujan/Videos/Captures/output.avi')\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e7bfc-b161-4664-99d6-2b5e56a6ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound  # Import the winsound module\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video\n",
    "    if playing_video:\n",
    "        # Capture video frames\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Convert frame to RGB format\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert frame to PIL Image\n",
    "            image = Image.fromarray(frame)\n",
    "            # Convert PIL Image to ImageTk format\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            \n",
    "            # Update the canvas image\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            \n",
    "            # Call this function again after a delay\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            # If video ends, release the capture object\n",
    "            cap.release()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()  # Play the listening sound\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)  # Give Rasa some time to start\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                speak(response)\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r'\"C:\\Users\\rujan\\Music\\0-02-03-a74027f96903b52ad94a07031d41acfce56351bc07dc48dd7ceaa9b39cf188c9_7aef05336d191c9d.mp4\"')\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca449b9-c5d7-45b8-a697-968ec761c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                speak(response)\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures\\bot.webm\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Start the video\n",
    "start_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663a3c6-0846-48b7-88e6-a4f54e59fa99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998d7ed-eb4f-4692-b170-a511dbaae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures\\bot.webm\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2128dee-b200-4268-a0bc-7ea3ab108aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27552409-c8e5-44b7-83be-71cbd17697c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import os\n",
    "import time\n",
    "import pyodbc\n",
    "import mysql.connector\n",
    "import warnings\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from mysql.connector import Error\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='khadgi986',\n",
    "    database='kisthack'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "citizenship_no = None\n",
    "full_name = None\n",
    "date_of_birth = None\n",
    "birth_place = None\n",
    "address = None\n",
    "\n",
    "def  capture():\n",
    "    \n",
    "\n",
    "    # Define the path where you want to save the video\n",
    "    output_dir = 'C:/Users/subad/OneDrive/Desktop/New folder (2)/Superlatives/captures' \n",
    "    img_path = 'C:/Users/subad/OneDrive/Desktop/New folder (2)/Superlatives/captures/final_frame.jpg' \n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_file = os.path.join(output_dir, 'final_frame.jpg')\n",
    "    output_file = os.path.join(output_dir, 'output.avi')\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Use 'XVID' codec\n",
    "    out = cv2.VideoWriter(output_file, fourcc, 20.0, (640, 480))\n",
    "    \n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video device\")\n",
    "        exit()\n",
    "    \n",
    "    # Set the width and height of the frame\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    # Countdown duration in seconds\n",
    "    countdown_duration = 10\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Define the rectangle parameters\n",
    "    top_left = (50, 50)\n",
    "    bottom_right = (600, 400)\n",
    "    color = (255, 0, 0)  # Blue color in BGR\n",
    "    thickness = 2  # Thickness of the rectangle border\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Draw the rectangle on the frame\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, thickness)\n",
    "    \n",
    "            # Calculate the elapsed time and countdown value\n",
    "            elapsed_time = time.time() - start_time\n",
    "            countdown_value = max(0, countdown_duration - int(elapsed_time))\n",
    "    \n",
    "            # Define the countdown text and its position\n",
    "            countdown_text = str(countdown_value)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 2\n",
    "            font_color = (0, 255, 0)  # Green color in BGR\n",
    "            font_thickness = 3\n",
    "            text_size = cv2.getTextSize(countdown_text, font, font_scale, font_thickness)[0]\n",
    "            text_x = (top_left[0] + bottom_right[0] - text_size[0]) // 2\n",
    "            text_y = (top_left[1] + bottom_right[1] + text_size[1]) // 2\n",
    "    \n",
    "            # Put the countdown text on the frame\n",
    "            cv2.putText(frame, countdown_text, (text_x, text_y), font, font_scale, font_color, font_thickness)\n",
    "    \n",
    "            # Write the frame to the output file\n",
    "            out.write(frame)\n",
    "    \n",
    "            # Display the frame\n",
    "            cv2.imshow('frame', frame)\n",
    "    \n",
    "            # Break the loop on 'q' key press or when countdown reaches zero\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or countdown_value == 0:\n",
    "                if countdown_value == 0:\n",
    "                    # Save the last frame within the rectangle as an image\n",
    "                    roi = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "                    cv2.imwrite(image_file, roi)\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release the webcam and file writer\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "capture()\n",
    "img_path = 'C:/Users/subad/OneDrive/Desktop/New folder (2)/Superlatives/captures/final_frame.jpg' \n",
    "capture()\n",
    "def ocrscnphoto():\n",
    "    print()\n",
    "    \n",
    "citizenship_no = \"17-01-77-05501\"\n",
    "full_name = \"ASHOK SHAH\"\n",
    "date_of_birth = \"2003 SEP 26\"\n",
    "birth_place = \"Sonigama - 2,Dhanusha\"\n",
    "address = \"Hansapur - 9,Dhanusha\"\n",
    "\n",
    "def prescanned():\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    reader = easyocr.Reader(['en'], gpu = True)\n",
    "    text = reader.readtext(image_path)\n",
    "    print(text)# Initialize an empty list to store the extracted strings\n",
    "    extracted_strings = []\n",
    "    \n",
    "    # Iterate over each tuple in processed_data\n",
    "    for item in text:\n",
    "        # Extract the text from the tuple and append it to the list\n",
    "        extracted_strings.append(item[1])\n",
    "    \n",
    "    # Print the extracted strings\n",
    "    # for string in extracted_strings:\n",
    "        # print(string)\n",
    "    \n",
    "    \n",
    "    citizenship_no = extracted_strings[2][1:]\n",
    "    sex = extracted_strings[3][5:]\n",
    "    full_name = extracted_strings[5]\n",
    "    date_of_birth = extracted_strings[7][-4:]+ \" \"+ extracted_strings[8][-3:]+ \" \"+ extracted_strings[9][-2:] \n",
    "    birth_place = extracted_strings[13]+ \"-\"+ extracted_strings[14][-2:]+ \",\"+ extracted_strings[11][10:]\n",
    "    address = extracted_strings[18]+ \"-\"+ extracted_strings[19][-2:]+ \",\"+ extracted_strings[16][10:]\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    # Print the extracted information\n",
    "    print(f\"Citizenship No: {citizenship_no}\")\n",
    "    print(f\"Full Name: {full_name}\")\n",
    "    print(f\"Date of Birth: {date_of_birth}\")\n",
    "    print(f\"Birth Place: {birth_place}\")\n",
    "    print(f\"Permanent Address: {address}\")\n",
    "\n",
    "img_path = 'C:/Users/subad/OneDrive/Desktop/New folder (2)/Superlatives/captures/final_frame.jpg' \n",
    "print(f\"Citizenship No: {citizenship_no}\")\n",
    "print(f\"Full Name: {full_name}\")\n",
    "print(f\"Date of Birth: {date_of_birth}\")\n",
    "print(f\"Birth Place: {birth_place}\")\n",
    "print(f\"Permanent Address: {address}\")\n",
    "\n",
    "    \n",
    "email = \"something@gm.com\"\n",
    "number = \"9876543210\"\n",
    "\n",
    "def insertdata():\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='cpktnwt',\n",
    "        database='kisthack'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    sql_insert_base64_query = \"\"\" INSERT INTO student\n",
    "                                      ( name, citizenship_number, number, address, email, DOB, birthplace, photo) \n",
    "                                      VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "    \n",
    "            \n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "            # Convert data into tuple format\n",
    "    insert_base64_tuple = ( full_name, citizenship_no, number, address, email, date_of_birth, birth_place, base64_image)\n",
    "    cursor.execute(sql_insert_base64_query, insert_base64_tuple)\n",
    "    connection.commit()\n",
    "    \n",
    "    print(\"Record inserted successfully\")\n",
    "       \n",
    "insertdata()\n",
    "cursor.execute(\"SELECT * FROM student\")\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3951ff-9f06-4474-9c08-a0c2dd0e0831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635352d-7c35-4af0-abca-34d9cab17f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d712c-ab54-49e7-a62b-e04498fa3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def capture(output_dir='captures', countdown_duration=10):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_file = os.path.join(output_dir, 'final_frame.jpg')\n",
    "    output_file = os.path.join(output_dir, 'output.avi')\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, 20.0, (640, 480))\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video device\")\n",
    "        return None\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    top_left = (50, 50)\n",
    "    bottom_right = (600, 400)\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, thickness)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            countdown_value = max(0, countdown_duration - int(elapsed_time))\n",
    "            countdown_text = str(countdown_value)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 2\n",
    "            font_color = (0, 255, 0)\n",
    "            font_thickness = 3\n",
    "            text_size = cv2.getTextSize(countdown_text, font, font_scale, font_thickness)[0]\n",
    "            text_x = (top_left[0] + bottom_right[0] - text_size[0]) // 2\n",
    "            text_y = (top_left[1] + bottom_right[1] + text_size[1]) // 2\n",
    "            cv2.putText(frame, countdown_text, (text_x, text_y), font, font_scale, font_color, font_thickness)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or countdown_value == 0:\n",
    "                if countdown_value == 0:\n",
    "                    roi = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "                    cv2.imwrite(image_file, roi)\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa84266-54eb-44e2-8994-8c62c908a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "def ocr_scan(image_path):\n",
    "    reader = easyocr.Reader(['en'], gpu=True)\n",
    "    text = reader.readtext(image_path)\n",
    "    extracted_strings = [item[1] for item in text]\n",
    "    \n",
    "    citizenship_no = extracted_strings[2][1:]\n",
    "    sex = extracted_strings[3][5:]\n",
    "    full_name = extracted_strings[5]\n",
    "    date_of_birth = extracted_strings[7][-4:] + \" \" + extracted_strings[8][-3:] + \" \" + extracted_strings[9][-2:]\n",
    "    birth_place = extracted_strings[13] + \"-\" + extracted_strings[14][-2:] + \",\" + extracted_strings[11][10:]\n",
    "    address = extracted_strings[18] + \"-\" + extracted_strings[19][-2:] + \",\" + extracted_strings[16][10:]\n",
    "    \n",
    "    return {\n",
    "        \"citizenship_no\": citizenship_no,\n",
    "        \"full_name\": full_name,\n",
    "        \"date_of_birth\": date_of_birth,\n",
    "        \"birth_place\": birth_place,\n",
    "        \"address\": address\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8a4a8-018f-4981-b4d0-78d3d9a7135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import base64\n",
    "\n",
    "def insert_data_to_db(full_name, citizenship_no, number, address, email, date_of_birth, birth_place, image_path):\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='khadgi986',\n",
    "        database='kisthack'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    sql_insert_base64_query = \"\"\"INSERT INTO student\n",
    "                                 (name, citizenship_number, number, address, email, DOB, birthplace, photo)\n",
    "                                 VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    insert_base64_tuple = (full_name, citizenship_no, number, address, email, date_of_birth, birth_place, base64_image)\n",
    "    cursor.execute(sql_insert_base64_query, insert_base64_tuple)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Record inserted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ba99a-9b85-4287-8580-f6a62263ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def capture(output_dir='captures', countdown_duration=10):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_file = os.path.join(output_dir, 'final_frame.jpg')\n",
    "    output_file = os.path.join(output_dir, 'output.avi')\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, 20.0, (640, 480))\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video device\")\n",
    "        return None\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    top_left = (50, 50)\n",
    "    bottom_right = (600, 400)\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, thickness)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            countdown_value = max(0, countdown_duration - int(elapsed_time))\n",
    "            countdown_text = str(countdown_value)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 2\n",
    "            font_color = (0, 255, 0)\n",
    "            font_thickness = 3\n",
    "            text_size = cv2.getTextSize(countdown_text, font, font_scale, font_thickness)[0]\n",
    "            text_x = (top_left[0] + bottom_right[0] - text_size[0]) // 2\n",
    "            text_y = (top_left[1] + bottom_right[1] + text_size[1]) // 2\n",
    "            cv2.putText(frame, countdown_text, (text_x, text_y), font, font_scale, font_color, font_thickness)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or countdown_value == 0:\n",
    "                if countdown_value == 0:\n",
    "                    roi = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "                    cv2.imwrite(image_file, roi)\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return image_file\n",
    "\n",
    "import easyocr\n",
    "\n",
    "def ocr_scan(image_path):\n",
    "    reader = easyocr.Reader(['en'], gpu=True)\n",
    "    text = reader.readtext(image_path)\n",
    "    extracted_strings = [item[1] for item in text]\n",
    "    \n",
    "    citizenship_no = extracted_strings[2][1:]\n",
    "    sex = extracted_strings[3][5:]\n",
    "    full_name = extracted_strings[5]\n",
    "    date_of_birth = extracted_strings[7][-4:] + \" \" + extracted_strings[8][-3:] + \" \" + extracted_strings[9][-2:]\n",
    "    birth_place = extracted_strings[13] + \"-\" + extracted_strings[14][-2:] + \",\" + extracted_strings[11][10:]\n",
    "    address = extracted_strings[18] + \"-\" + extracted_strings[19][-2:] + \",\" + extracted_strings[16][10:]\n",
    "    \n",
    "    return {\n",
    "        \"citizenship_no\": citizenship_no,\n",
    "        \"full_name\": full_name,\n",
    "        \"date_of_birth\": date_of_birth,\n",
    "        \"birth_place\": birth_place,\n",
    "        \"address\": address\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "import mysql.connector\n",
    "import base64\n",
    "\n",
    "def insert_data_to_db(full_name, citizenship_no, number, address, email, date_of_birth, birth_place, image_path):\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='khadgi986',\n",
    "        database='kisthack'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    sql_insert_base64_query = \"\"\"INSERT INTO student\n",
    "                                 (name, citizenship_number, number, address, email, DOB, birthplace, photo)\n",
    "                                 VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    insert_base64_tuple = (full_name, citizenship_no, number, address, email, date_of_birth, birth_place, base64_image)\n",
    "    cursor.execute(sql_insert_base64_query, insert_base64_tuple)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Record inserted successfully\")\n",
    "\n",
    "\n",
    "\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\LEGION\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            return None\n",
    "\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\"sender\": \"user\", \"message\": question}\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                if \"capture\" in question.lower():\n",
    "                    image_path = capture()\n",
    "                    if image_path:\n",
    "                        ocr_result = ocr_scan(image_path)\n",
    "                        speak(f\"Scanned data: {ocr_result}\")\n",
    "                        insert_data_to_db(ocr_result['full_name'], ocr_result['citizenship_no'], \"9876543210\", ocr_result['address'], \"something@gm.com\", ocr_result['date_of_birth'], ocr_result['birth_place'], image_path)\n",
    "                        speak(\"Data has been saved to the database.\")\n",
    "                else:\n",
    "                    speak(response)\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Chatbot\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures\\bot.webm\")\n",
    "rasa_process = run_rasa_shell()\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "root.mainloop()\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2efa3fff-9286-40ca-b1a8-e332fc9ff67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import os\n",
    "import time\n",
    "import pyodbc\n",
    "import mysql.connector\n",
    "import warnings\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from mysql.connector import Error\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='khadgi986',\n",
    "    database='kisthack'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "citizenship_no = None\n",
    "full_name = None\n",
    "date_of_birth = None\n",
    "birth_place = None\n",
    "address = None\n",
    "\n",
    "def  capture():\n",
    "    \n",
    "\n",
    "    # Define the path where you want to save the video\n",
    "    output_dir = r'C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures' \n",
    "    img_path = r'C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures\\final_frame.jpg' \n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_file = os.path.join(output_dir, 'final_frame.jpg')\n",
    "    output_file = os.path.join(output_dir, 'output.avi')\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Use 'XVID' codec\n",
    "    out = cv2.VideoWriter(output_file, fourcc, 20.0, (640, 480))\n",
    "    \n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video device\")\n",
    "        exit()\n",
    "    \n",
    "    # Set the width and height of the frame\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    # Countdown duration in seconds\n",
    "    countdown_duration = 10\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Define the rectangle parameters\n",
    "    top_left = (50, 50)\n",
    "    bottom_right = (600, 400)\n",
    "    color = (255, 0, 0)  # Blue color in BGR\n",
    "    thickness = 2  # Thickness of the rectangle border\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Draw the rectangle on the frame\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, thickness)\n",
    "    \n",
    "            # Calculate the elapsed time and countdown value\n",
    "            elapsed_time = time.time() - start_time\n",
    "            countdown_value = max(0, countdown_duration - int(elapsed_time))\n",
    "    \n",
    "            # Define the countdown text and its position\n",
    "            countdown_text = str(countdown_value)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 2\n",
    "            font_color = (0, 255, 0)  # Green color in BGR\n",
    "            font_thickness = 3\n",
    "            text_size = cv2.getTextSize(countdown_text, font, font_scale, font_thickness)[0]\n",
    "            text_x = (top_left[0] + bottom_right[0] - text_size[0]) // 2\n",
    "            text_y = (top_left[1] + bottom_right[1] + text_size[1]) // 2\n",
    "    \n",
    "            # Put the countdown text on the frame\n",
    "            cv2.putText(frame, countdown_text, (text_x, text_y), font, font_scale, font_color, font_thickness)\n",
    "    \n",
    "            # Write the frame to the output file\n",
    "            out.write(frame)\n",
    "    \n",
    "            # Display the frame\n",
    "            cv2.imshow('frame', frame)\n",
    "    \n",
    "            # Break the loop on 'q' key press or when countdown reaches zero\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or countdown_value == 0:\n",
    "                if countdown_value == 0:\n",
    "                    # Save the last frame within the rectangle as an image\n",
    "                    roi = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "                    cv2.imwrite(image_file, roi)\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release the webcam and file writer\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "img_path = r\"C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures\\final_frame.jpg\"\n",
    "\n",
    "def ocrscnphoto():\n",
    "    print()\n",
    "\n",
    "def ocrscanphoto():\n",
    "    img_path = 'C:/Users/subad/OneDrive/Desktop/New folder (2)/Superlatives/captures/final_frame.jpg'\n",
    "    reader = easyocr.Reader(['en'], gpu = False)\n",
    "    text = reader.readtext(img_path)\n",
    "    \n",
    "    \n",
    "    print(text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize an empty list to store the extracted strings\n",
    "    extracted_strings = []\n",
    "    \n",
    "    # Iterate over each tuple in processed_data\n",
    "    for item in text:\n",
    "        # Extract the text from the tuple and append it to the list\n",
    "        extracted_strings.append(item[1])\n",
    "    \n",
    "    # Print the extracted strings\n",
    "    for string in extracted_strings:\n",
    "        print(string)\n",
    "    \n",
    "    \n",
    "    citizenship_no = extracted_strings[2][1:]\n",
    "    sex = extracted_strings[3][5:]\n",
    "    full_name = extracted_strings[5]\n",
    "    date_of_birth = extracted_strings[7][-4:]+ \" \"+ extracted_strings[8][-3:]+ \" \"+ extracted_strings[9][-2:] \n",
    "    birth_place = extracted_strings[13]+ \"-\"+ extracted_strings[14][-2:]+ \",\"+ extracted_strings[11][10:]\n",
    "    address = extracted_strings[18]+ \"-\"+ extracted_strings[19][-2:]+ \",\"+ extracted_strings[16][10:]\n",
    "\n",
    "ocrscnphoto()\n",
    "\n",
    "citizenship_no = \"17-01-77-05501\"\n",
    "full_name = \"ASHOK SHAH\"\n",
    "date_of_birth = \"2003 SEP 26\"\n",
    "birth_place = \"Sonigama - 2,Dhanusha\"\n",
    "address = \"Hansapur - 9,Dhanusha\"\n",
    "\n",
    "def prescanned():\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    reader = easyocr.Reader(['en'], gpu = True)\n",
    "    text = reader.readtext(image_path)\n",
    "    print(text)# Initialize an empty list to store the extracted strings\n",
    "    extracted_strings = []\n",
    "    \n",
    "    # Iterate over each tuple in processed_data\n",
    "    for item in text:\n",
    "        # Extract the text from the tuple and append it to the list\n",
    "        extracted_strings.append(item[1])\n",
    "    \n",
    "    # Print the extracted strings\n",
    "    # for string in extracted_strings:\n",
    "        # print(string)\n",
    "    \n",
    "    \n",
    "    citizenship_no = extracted_strings[2][1:]\n",
    "    sex = extracted_strings[3][5:]\n",
    "    full_name = extracted_strings[5]\n",
    "    date_of_birth = extracted_strings[7][-4:]+ \" \"+ extracted_strings[8][-3:]+ \" \"+ extracted_strings[9][-2:] \n",
    "    birth_place = extracted_strings[13]+ \"-\"+ extracted_strings[14][-2:]+ \",\"+ extracted_strings[11][10:]\n",
    "    address = extracted_strings[18]+ \"-\"+ extracted_strings[19][-2:]+ \",\"+ extracted_strings[16][10:]\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    # Print the extracted information\n",
    "    print(f\"Citizenship No: {citizenship_no}\")\n",
    "    print(f\"Full Name: {full_name}\")\n",
    "    print(f\"Date of Birth: {date_of_birth}\")\n",
    "    print(f\"Birth Place: {birth_place}\")\n",
    "    print(f\"Permanent Address: {address}\")\n",
    "\n",
    "img_path = r\"C:\\Users\\LEGION\\Desktop\\virtual_campus\\Superlatives\\captures\\final_frame.jpg\"\n",
    "print(f\"Citizenship No: {citizenship_no}\")\n",
    "print(f\"Full Name: {full_name}\")\n",
    "print(f\"Date of Birth: {date_of_birth}\")\n",
    "print(f\"Birth Place: {birth_place}\")\n",
    "print(f\"Permanent Address: {address}\")\n",
    "\n",
    "    \n",
    "email = \"something@gm.com\"\n",
    "number = \"9876543210\"\n",
    "image_path=r\"C:\\Users\\LEGION\\Downloads\\back.jpg\"\n",
    "def insertdata():\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='khadgi986',\n",
    "        database='kisthack'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    sql_insert_base64_query = \"\"\" INSERT INTO student\n",
    "                                      ( name, citizenship_number, number, address, email, DOB, birthplace, photo) \n",
    "                                      VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "    \n",
    "            \n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "            # Convert data into tuple format\n",
    "    insert_base64_tuple = ( full_name, citizenship_no, number, address, email, date_of_birth, birth_place, base64_image)\n",
    "    cursor.execute(sql_insert_base64_query, insert_base64_tuple)\n",
    "    connection.commit()\n",
    "    \n",
    "    print(\"Record inserted successfully\")\n",
    "       \n",
    "insertdata()\n",
    "cursor.execute(\"SELECT * FROM student\")\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a240464-16c3-4d9a-aa2a-8fd0c10de3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: is associated\n",
      "Bot: Yes ayush  is gay and ashok are lesbian . they are fucking asshole.crybaby\n",
      "Listening for your question...\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\LEGION\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            return None\n",
    "\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\"sender\": \"user\", \"message\": question}\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "def get_input(prompt):\n",
    "    speak(prompt)\n",
    "    input_data = recognize_speech()\n",
    "    return input_data\n",
    "\n",
    "def enroll_user():\n",
    "    speak(\"Hello, I will first take a picture of the backside of your citizenship.  Make sure you place it inside the rectangle within the  10 second countdown\")\n",
    "    image_path = capture()\n",
    "    speak(\" I will first ask for your phone number.\")\n",
    "    phone_number = get_input(\"Please say your phone number.\")\n",
    "    if phone_number:\n",
    "        speak(f\"You said: {phone_number}. Now I will ask for your email.\")\n",
    "        email = get_input(\"Please say your email address.\")\n",
    "        if email:\n",
    "            speak(f\"You said: {email}. What faculties are you chossing.\")\n",
    "            faculties=get_input(\"Please say your choice of faculty.\")\n",
    "            if faculties:\n",
    "                speak(f\"Thank you. You have been enrolled for {faculties} with phone number {phone_number}and email {email}.\")\n",
    "            else:\n",
    "                speak(\"I couldn't understand your email. Please try again.\")\n",
    "        else:\n",
    "            speak(\"I couldn't understand your phone number. Please try again.\")\n",
    "    else:\n",
    "            speak(\"I couldn't understand your phone number. Please try again.\")\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            elif \"enroll\" in question.lower():\n",
    "                enroll_user()\n",
    "\n",
    "            elif \"is subham gay\" in question.lower():\n",
    "                speak(\"Tyo muji chakka nai ho\")\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                if \"capture\" in question.lower():\n",
    "                    image_path = capture()\n",
    "                    speak(\"Data has been saved to the database.\")\n",
    "                    if image_path:\n",
    "                        ocr_result = ocr_scan(image_path)\n",
    "                        speak(f\"Scanned data: {ocr_result}\")\n",
    "                        insert_data_to_db(ocr_result['full_name'], ocr_result['citizenship_no'], \"9876543210\", ocr_result['address'], \"something@gm.com\", ocr_result['date_of_birth'], ocr_result['birth_place'], image_path)\n",
    "                        speak(\"Data has been saved to the database.\")\n",
    "                else:\n",
    "                    start_video()\n",
    "                    speak(response)\n",
    "                    stop_video()\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Chatbot\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack() \n",
    "\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\LEGION\\Desktop\\New folder\\Superlatives\\captures\\bot.webm\")\n",
    "rasa_process = run_rasa_shell()\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "start_video()\n",
    "root.mainloop()\n",
    "print(\"Program ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e28ac-5114-443e-b612-cdc3f3f0ec67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
