{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4807e5-92cc-41e6-98aa-13dd812cb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: what are the courses of LLB what are the courses available\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df60c6-6108-4956-a929-22456b1d6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: what are the courses available\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "You said: stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9345a-1874-445c-bf94-ff94cfe3127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you?\n",
      "Listening for your question...\n",
      "You said: I am fine\n",
      "Bot: Great, carry on! Ask any thing about college.\n",
      "Listening for your question...\n",
      "You said: tell me about all the available courses\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "You said: ok stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        # Set a lower duration for ambient noise adjustment to speed up the process\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc50ca-9feb-4df1-b64a-eae4878c7dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you? Absolutely!\n",
      "Listening for your question...\n",
      "You said: I am fine\n",
      "Bot: Great, carry on! Ask any thing about college. Cool!\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: hey there\n",
      "Bot: Hey! How are you? Yup!\n",
      "Listening for your question...\n",
      "You said: knock knock stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set TTS voice settings\n",
    "def set_tts_voice(engine):\n",
    "    voices = engine.getProperty('voices')\n",
    "    for voice in voices:\n",
    "        if \"female\" in voice.name.lower():  # Choose a female voice for a friendly tone, can be adjusted based on preference\n",
    "            engine.setProperty('voice', voice.id)\n",
    "            break\n",
    "    engine.setProperty('volume', 0.9)  # Set volume to 90% of maximum\n",
    "    engine.setProperty('pitch', 1.2)   # Increase pitch slightly for a more cheerful tone\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "set_tts_voice(engine)  # Set TTS voice settings\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        # Set a lower duration for ambient noise adjustment to speed up the process\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to make responses more casual\n",
    "def make_response_casual(response):\n",
    "    casual_phrases = [\n",
    "        \"Sure thing!\", \"Alright!\", \"You got it!\", \"No problem!\", \"Absolutely!\", \"Gotcha!\", \"Cool!\", \"Alrighty!\", \"Of course!\", \"Yup!\"\n",
    "    ]\n",
    "    if response:\n",
    "        casual_response = f\"{response} {np.random.choice(casual_phrases)}\"\n",
    "        return casual_response\n",
    "    return response\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return make_response_casual(bot_responses[0]['text'])\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd9e2d1-4b54-49c9-82cb-e88f20328dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: hello\n",
      "Listening for your question...\n",
      "You said: I am fine I am fine\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: stop\n",
      "Program ended.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "import fitz  # PyMuPDF\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Function to open a file dialog and select a PDF file\n",
    "def choose_pdf():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "    if file_path:\n",
    "        read_pdf(file_path)\n",
    "\n",
    "# Function to read the PDF content\n",
    "def read_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    pdf_text = \"\"\n",
    "    for page in doc:\n",
    "        pdf_text += page.get_text()\n",
    "    process_pdf_content(pdf_text)\n",
    "\n",
    "# Function to process the PDF content\n",
    "def process_pdf_content(content):\n",
    "    # Tokenize the content into sentences\n",
    "    sentences = sent_tokenize(content)\n",
    "    # Store the sentences in a global variable or process them as needed\n",
    "    global pdf_sentences\n",
    "    pdf_sentences = sentences\n",
    "    speak(\"PDF content has been processed.\")\n",
    "\n",
    "# Function to respond to questions based on the PDF content\n",
    "def respond_from_pdf(question):\n",
    "    global pdf_sentences\n",
    "    if not pdf_sentences:\n",
    "        return \"No PDF content available.\"\n",
    "\n",
    "    # Simple keyword matching for demonstration\n",
    "    question_tokens = word_tokenize(question.lower())\n",
    "    for sentence in pdf_sentences:\n",
    "        sentence_tokens = word_tokenize(sentence.lower())\n",
    "        if any(token in sentence_tokens for token in question_tokens):\n",
    "            return sentence\n",
    "    return \"Sorry, I couldn't find the information in the PDF.\"\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Create a button to choose a PDF file\n",
    "choose_pdf_button = tk.Button(root, text=\"Choose PDF\", command=choose_pdf)\n",
    "choose_pdf_button.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6147ae19-79de-4b41-88f9-97384f98310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Program ended.\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "from PyPDF2 import PdfReader\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                speak(response)\n",
    "\n",
    "# Function to upload and read PDF\n",
    "def upload_pdf():\n",
    "    global pdf_text\n",
    "    pdf_file_path = filedialog.askopenfilename(filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "    if pdf_file_path:\n",
    "        pdf_text = read_pdf(pdf_file_path)\n",
    "        messagebox.showinfo(\"PDF Upload\", \"PDF uploaded successfully!\")\n",
    "\n",
    "# Function to read PDF content\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Function to answer questions based on PDF content\n",
    "def answer_from_pdf(question):\n",
    "    sentences = sent_tokenize(pdf_text)\n",
    "    for sentence in sentences:\n",
    "        if question.lower() in sentence.lower():\n",
    "            return sentence\n",
    "    return \"I couldn't find an answer in the PDF.\"\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter PDF Reader\")\n",
    "root.geometry(\"400x300\")\n",
    "\n",
    "# Create a button to upload PDF\n",
    "upload_button = tk.Button(root, text=\"Upload PDF\", command=upload_pdf)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28d0f7-cc6d-49e6-bfff-8657f0b04472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757f087-217c-44c2-94b3-ca1c7d93102a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
