{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc5313-bdec-4d8b-a865-9996320b736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you?\n",
      "Listening for your question...\n",
      "You said: what are the courses available\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "You said: stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video\n",
    "    if playing_video:\n",
    "        # Capture video frames\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Convert frame to RGB format\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert frame to PIL Image\n",
    "            image = Image.fromarray(frame)\n",
    "            # Convert PIL Image to ImageTk format\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            \n",
    "            # Update the canvas image\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            \n",
    "            # Call this function again after a delay\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            # If video ends, release the capture object\n",
    "            cap.release()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening for your question...\")\n",
    "        speak(\"Listening for your question...\")\n",
    "        audio_data = recognizer.listen(source)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "            speak(\"I could not understand what you said. Please try again.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)  # Give Rasa some time to start\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                response = communicate_with_rasa(question)\n",
    "                print(f\"Bot: {response}\")\n",
    "                speak(response)\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture('C:/Users/rujan/Videos/Captures/output.avi')\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4807e5-92cc-41e6-98aa-13dd812cb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you?\n",
      "Listening for your question...\n",
      "You said: I am fine\n",
      "Bot: Great, carry on! Ask any thing about college.\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you?\n",
      "Listening for your question...\n",
      "You said: I am fine\n",
      "Bot: Great, carry on! Ask any thing about college.\n",
      "Listening for your question...\n",
      "You said: how is Africa\n",
      "Bot: Sorry, I'm not sure how to help with that.\n",
      "Listening for your question...\n",
      "You said: how is software Erica\n",
      "Bot: Sorry, I'm not sure how to help with that.\n",
      "Listening for your question...\n",
      "You said: about the college of Erica\n",
      "Bot: Sorry, I'm not sure how to help with that.\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: stop\n",
      "Program ended.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df60c6-6108-4956-a929-22456b1d6b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
