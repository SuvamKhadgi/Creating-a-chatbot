{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4807e5-92cc-41e6-98aa-13dd812cb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: what are the courses of LLB what are the courses available\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df60c6-6108-4956-a929-22456b1d6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: what are the courses available\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "You said: stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9345a-1874-445c-bf94-ff94cfe3127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you?\n",
      "Listening for your question...\n",
      "You said: I am fine\n",
      "Bot: Great, carry on! Ask any thing about college.\n",
      "Listening for your question...\n",
      "You said: tell me about all the available courses\n",
      "Bot: We offer the following courses: Science,Management,BIT,BBA,BIM,BBS,MBS,BSc.Microbiology,MSc Microbiology,MIT.\n",
      "Listening for your question...\n",
      "You said: ok stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        # Set a lower duration for ambient noise adjustment to speed up the process\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return bot_responses[0]['text']\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc50ca-9feb-4df1-b64a-eae4878c7dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: hello\n",
      "Bot: Hey! How are you? Absolutely!\n",
      "Listening for your question...\n",
      "You said: I am fine\n",
      "Bot: Great, carry on! Ask any thing about college. Cool!\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "Listening for your question...\n",
      "You said: hey there\n",
      "Bot: Hey! How are you? Yup!\n",
      "Listening for your question...\n",
      "You said: knock knock stop\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "import winsound\n",
    "\n",
    "# Initialize the recognizer and TTS engine\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set speech rate\n",
    "def set_speech_rate(rate):\n",
    "    engine.setProperty('rate', rate)\n",
    "\n",
    "# Set TTS voice settings\n",
    "def set_tts_voice(engine):\n",
    "    voices = engine.getProperty('voices')\n",
    "    for voice in voices:\n",
    "        if \"female\" in voice.name.lower():  # Choose a female voice for a friendly tone, can be adjusted based on preference\n",
    "            engine.setProperty('voice', voice.id)\n",
    "            break\n",
    "    engine.setProperty('volume', 0.9)  # Set volume to 90% of maximum\n",
    "    engine.setProperty('pitch', 1.2)   # Increase pitch slightly for a more cheerful tone\n",
    "\n",
    "# Set speech rate to a slower speed (e.g., 150 words per minute)\n",
    "set_speech_rate(150)\n",
    "set_tts_voice(engine)  # Set TTS voice settings\n",
    "\n",
    "# Initialize variables for controlling video playback\n",
    "playing_video = False\n",
    "\n",
    "# Function to play video in Tkinter window\n",
    "def play_video():\n",
    "    global playing_video, cap\n",
    "    if playing_video:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Resize frame to fit the canvas\n",
    "            frame = cv2.resize(frame, (canvas_width, canvas_height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(frame)\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "            root.after(10, play_video)\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            play_video()\n",
    "\n",
    "# Function to start playing the video\n",
    "def start_video():\n",
    "    global playing_video\n",
    "    playing_video = True\n",
    "    play_video()\n",
    "\n",
    "# Function to stop playing the video\n",
    "def stop_video():\n",
    "    global playing_video\n",
    "    playing_video = False\n",
    "\n",
    "# Function to make the bot speak\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to play a sound indicating that the program is listening\n",
    "def play_listening_sound():\n",
    "    winsound.PlaySound(r\"C:\\Users\\rujan\\Downloads\\voice-assistant-sound-name-unknown.wav\", winsound.SND_FILENAME)\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        # Set a lower duration for ambient noise adjustment to speed up the process\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening for your question...\")\n",
    "        play_listening_sound()\n",
    "        audio_data = recognizer.listen(source, timeout=300)\n",
    "        try:\n",
    "            question = recognizer.recognize_google(audio_data)\n",
    "            print(f\"You said: {question}\")\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            speak(\"There was an error with the speech recognition service.\")\n",
    "            return None\n",
    "\n",
    "# Function to make responses more casual\n",
    "def make_response_casual(response):\n",
    "    casual_phrases = [\n",
    "        \"Sure thing!\", \"Alright!\", \"You got it!\", \"No problem!\", \"Absolutely!\", \"Gotcha!\", \"Cool!\", \"Alrighty!\", \"Of course!\", \"Yup!\"\n",
    "    ]\n",
    "    if response:\n",
    "        casual_response = f\"{response} {np.random.choice(casual_phrases)}\"\n",
    "        return casual_response\n",
    "    return response\n",
    "\n",
    "# Function to communicate with the Rasa server\n",
    "def communicate_with_rasa(question):\n",
    "    url = \"http://localhost:5005/webhooks/rest/webhook\"\n",
    "    payload = {\n",
    "        \"sender\": \"user\",\n",
    "        \"message\": question\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        bot_responses = response.json()\n",
    "        if bot_responses:\n",
    "            return make_response_casual(bot_responses[0]['text'])\n",
    "    return \"Sorry, I couldn't get a response from the server.\"\n",
    "\n",
    "# Function to run the Rasa shell\n",
    "def run_rasa_shell():\n",
    "    speak(\"Starting Rasa shell.\")\n",
    "    process = subprocess.Popen([\"rasa\", \"run\"], shell=True)\n",
    "    time.sleep(5)\n",
    "    speak(\"Rasa server is up and running.\")\n",
    "    return process\n",
    "\n",
    "# Function to recognize speech and respond\n",
    "def recognize_and_respond():\n",
    "    while True:\n",
    "        question = recognize_speech()\n",
    "        if question:\n",
    "            if \"stop\" in question.lower():\n",
    "                speak(\"Stopping the program.\")\n",
    "                rasa_process.terminate()\n",
    "                break\n",
    "            else:\n",
    "                #start_video()  # Start video when a question is asked\n",
    "                response = communicate_with_rasa(question)\n",
    "                #stop_video()  # Stop video after question is processed\n",
    "                print(f\"Bot: {response}\")\n",
    "                start_video()\n",
    "                speak(response)\n",
    "                stop_video()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter Video Background\")\n",
    "canvas_width = 800\n",
    "canvas_height = 600\n",
    "root.geometry(f\"{canvas_width}x{canvas_height}\")\n",
    "\n",
    "# Create a canvas to display video frames\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height)\n",
    "canvas.pack()\n",
    "\n",
    "# Load video using OpenCV\n",
    "cap = cv2.VideoCapture(r\"C:/Users/rujan/Videos/Captures/output.avi\")\n",
    "\n",
    "# Start the Rasa server\n",
    "rasa_process = run_rasa_shell()\n",
    "\n",
    "# Start the recognition and response loop in a separate thread\n",
    "recognize_thread = threading.Thread(target=recognize_and_respond)\n",
    "recognize_thread.start()\n",
    "\n",
    "# Initially start and immediately stop the video to initialize the canvas\n",
    "start_video()\n",
    "stop_video()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "print(\"Program ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9e2d1-4b54-49c9-82cb-e88f20328dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
